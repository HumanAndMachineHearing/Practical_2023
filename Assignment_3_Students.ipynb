{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNc/9Xp6RyqAoDi3HhWMiVA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HumanAndMachineHearing/Practical_2023/blob/main/Assignment_3_Students.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Programming Assignment 3. Data pre-processing and exploring the ResNet-18 model**\n",
        "\n",
        "## 1. Introduction\n",
        "\n",
        "In Session 3, you will explore the ResNet-18 model structure, the files you need for training the model, and prepare your datasets (that is, a one-channel dataset and a three-channel dataset).\n",
        "\n",
        "* The paper by He et al. (2016) in which ResNet was originally introduced can be found [here](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf).\n",
        "* A helpful explanation of the Resnet paper can be found [here](https://debuggercafe.com/residual-neural-networks-resnets-paper-explanation/).\n",
        "* If you would like to know more about implementing ResNet-18 from scratch, have a look at the following [blogpost](https://https://debuggercafe.com/implementing-resnet18-in-pytorch-from-scratch/). The present code for the model is based largely on this implementation.\n",
        "\n",
        "**Practical Report**\n",
        "\n",
        "\n",
        "<p align = 'justify'> For this session, you are expected to add the output of and answers to the exercises as defined in the notebook to the Practical Report. A link to the templates for the practical reports can be found in the Readme file.\n",
        "\n"
      ],
      "metadata": {
        "id": "V-eYmdXN1gxC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparation\n",
        "\n",
        "Before starting with the exercises, import the libraries that are essential for this excerise."
      ],
      "metadata": {
        "id": "5Do7J7jfEhKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Machine learning framework\n",
        "import torch\n",
        "\n",
        "# Library for audio and signal processing with PyTorch\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T # for common audio processings and feature extractions\n",
        "import torchaudio.functional as F # Implements features as standalone functions\n",
        "\n",
        "# For manipulating directory paths\n",
        "import os\n",
        "\n",
        "# For working with datasets\n",
        "import pandas as pd\n",
        "\n",
        "# Plotting library\n",
        "import matplotlib.pyplot as plt\n",
        "# To embed plots within the notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# Scientific and vector computation for Python\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "T1dAj8frEggF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preparing data and metadata\n",
        "\n",
        "Generate a list of names of all sound clips in the datafolder to easily access data later."
      ],
      "metadata": {
        "id": "PPhtVuwIFSfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define file path to folder with .wav files\n",
        "filepath_snds = '/content/drive/MyDrive/soundclass_resnet18/audio'\n",
        "filepath_metadata = '/content/drive/MyDrive/soundclass_resnet18'\n",
        "\n",
        "# Create list of file IDs to cycle through data\n",
        "filename_csv = 'esc50_edited.csv'\n",
        "\n",
        "# Load csv file\n",
        "csv_data = pd.read_csv(os.path.join(filepath_csv,filename_csv),sep = ';')\n",
        "\n",
        "# Convert filenames to list\n",
        "file_IDs = csv_data['filename'].to_list()"
      ],
      "metadata": {
        "id": "ouk0YQkzFIb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Generate two audio feature data sets consisting of a single channel\n",
        "\n",
        "Code a routine which converts the .wav files into the desired sound feature with the required dimensions using the code from the previous sessions. Do this for two different sound features. Save each dataset into a separate folder.\n",
        "\n",
        "* Dimensions one-channel dataset: [1, 128, 128]"
      ],
      "metadata": {
        "id": "t9KkrY0PGv5d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRmO56h11dwQ"
      },
      "outputs": [],
      "source": [
        "# Routine to extract single sound feature and store in folder\n",
        "\n",
        "for count, value in enumerate(file_IDs):\n",
        "  # Add code to extract audio features\n",
        "\n",
        "  # Use torch.save() to save the resulting files. # This saves tensors with a .pt file extension."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. The Resnet-18 model\n",
        "\n",
        "<p align=\"justify\"> To train the Resnet-18 model, we use the files listed below. Have a look at the files to get acquainted with the materials.\n",
        "\n",
        "* **resnet18.py**: This file contains the code for building the Resnet Basic Blocks and the code for the Resnet module.  \n",
        "* **utils_resnet_esc50.py**: This file contains the utility scripts, i.e. the function definitions to load the training and validation dataset.\n",
        "* **training_utils_resnet_esc50_v2.py**: This file contains the function definitions for training and validation.\n",
        "* **train_resnet_esc50.py**: This script contains everything that is needed for training, i.e., importing the required modules, setting the training parameters, loading the model and executing training.\n",
        "\n",
        "**Exercise 3.1:**\n",
        "<p align = \"justify\"> (A) Describe the Resnet-18 model architecture in your practical report using the information from the sources mentioned at the top of the page.\n",
        "<p align = \"justify\"> (B) Explain why ResNet-18 is a suitable model for the present task and dataset or, if you think another model would be better suited to the current task and dataset, describe why you think your proposed model would give better results than Resnet-18."
      ],
      "metadata": {
        "id": "RmH5uxVS_zqr"
      }
    }
  ]
}