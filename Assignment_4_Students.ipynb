{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPB8uTiyFJVmWl/+OOhCStx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HumanAndMachineHearing/Practical_2023/blob/main/Assignment_4_Students.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Programming Assignment 4. Training on one-channel data**\n",
        "\n",
        "## 1. Introduction:\n",
        "<p align = \"justify\"> In the first three sessions, you have learned the meaning of various audio features and prepared two one-channel datasets for training the Resnet-18 model. In this session, you will train the ResNet-18 model on the first dataset.\n",
        "\n",
        "In case you do not have an account for Weights and Biases yet, have a look at the readme file to set this up.\n",
        "\n",
        "**Resources:**\n",
        "<p align = \"justify\">\n",
        "You can speed up training by changing the Colab runtime type to GPU in the upper right corner. In principle, this should be sufficient to let the model finish within a reasonable time frame (although perhaps not within the duration of one practical session).\n",
        "\n",
        "However, in case you would like to speed up training, you can  purchase Colab compute units or make use of a (paid) subscription to Colab (e.g., Colab Pro). More information about Colab options can be found [here](https://colab.research.google.com/signup).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yYd7l3wI2FE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparation:"
      ],
      "metadata": {
        "id": "BZ7SpeEYLtU7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJivcNAd2EYx"
      },
      "outputs": [],
      "source": [
        "# Install Weights and Biases in the environment to track training\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Log in to wandb (get your API key from User Settings --> Danger zone)"
      ],
      "metadata": {
        "id": "Q5SuHG26gsxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive or other location of where files are stored\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PoatlSqaIOIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory to folder that contains all required scripts\n",
        "%cd /content/drive/MyDrive/soundclass_resnet18/\n",
        "\n",
        "# Check whether this folder contains the required scripts.\n",
        "!ls"
      ],
      "metadata": {
        "id": "DyzEAx5hIWRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Training\n",
        "\n",
        "## Data\n",
        "Make sure that the data that you want to use for training, is stored in a folder 'Data' in the correct directory. Note that for training the model, a datasplit is generated in `train_resnet_esc50.py` in which 1500 sounds are used for training, 400 for validating, and 100 sounds are left out for evaluation at a later stage.\n",
        "\n",
        "## Preparation\n",
        "Set the following parameters in the file `train_resnet_esc50.py`\n",
        "* Filepath in `filepath = NAMEFILEPATH`\n",
        "* Name .csv metadata file in `filename = NAME_CSV_FILE`\n",
        "* Name project in `wandb.init(project = 'PROJECT_NAME')`\n",
        "* Name current training run in `wandb.run.name = 'RUN_NAME'`. Make sure to use a suitable name that informs you about the training parameters that you used (e.g., learning rate, batch size, etc.).\n",
        "* Name file for saving weights after training (last line of the script).\n",
        "\n",
        "## Training parameters\n",
        "In this practical, the parameters for training the Resnet-18 model are set to:\n",
        "\n",
        "* nr_channels = 1\n",
        "* learning rate = 0.0002\n",
        "* batch size = 32\n",
        "* epochs = 50\n",
        "* lr_scheduler = [40,60], gamma = .75 (Note that two steps are added in the lr_scheduler in case you would like to increase the number of epochs. In case you train for 50 epochs, it uses the first step only.).  \n",
        "\n",
        "To adjust these parameters, go to the file **train_resnet_esc50.py**.\n",
        "\n",
        "## Train\n",
        "Train the model by executing the cell below.\n",
        "\n",
        "Follow training progress on WandB.  \n"
      ],
      "metadata": {
        "id": "y6KeS33JGChd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "!python train_resnet_esc50.py"
      ],
      "metadata": {
        "id": "NnYf8GHeGkcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4.1:**\n",
        "<p align = \"justify\"> (A) Train the model on the one-channel data and describe your implementation (i.e., framework, training parameters, learning schedule, etc.) in the practical report. Look at existing ResNet papers (including the paper of He et al., 2016) to get a good idea of writing an 'Implementation' section.\n",
        "\n",
        "<p align = \"justify\"> (B) Describe training progress in the Practical Report. Include a plot of the combined training and validation loss and/or accuracy plot from WandB (see instruction below).  In case you train the model multiple times, describe your rationale for the chosen training parameters.   \n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**Formatting wandb plots:**\n",
        "* To change the formatting of the plot, click on the pencil icon in the graph.\n",
        "* To include two metrics in one plot (for example, training loss and validation loss), add extra variables in pencil --> Y.\n",
        "* To change the x-axis from steps to epochs, change the setting in pencil --> X.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**Training the model multiple times:**\n",
        "<br>\n",
        "In case you would like to train the model multiple times (e.g. with different audio features or using different parameters), you can add these results to the report. However, this is not needed for fulfilling the requirements of Practical report.\n"
      ],
      "metadata": {
        "id": "6Tn0EuAHLkvX"
      }
    }
  ]
}